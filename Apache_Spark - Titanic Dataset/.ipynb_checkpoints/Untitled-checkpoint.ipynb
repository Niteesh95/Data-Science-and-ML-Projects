{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0af347",
   "metadata": {},
   "source": [
    "# ML classification model - Titanic Dataset using pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0b3aa",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- survival: Survival\t0 = No, 1 = Yes\n",
    "- pclass: Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- Age: Age in years\t\n",
    "- sibsp: # of siblings / spouses aboard the Titanic\t\n",
    "- parch: # of parents / children aboard the Titanic\t\n",
    "- ticket: Ticket number\t\n",
    "- fare: Passenger fare\t\n",
    "- embarked: Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63001280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.2.1-bin-hadoop3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9adc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df3a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861f783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf54a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|  C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(filename, header=True, inferSchema=True)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bb8f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2918ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f478c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|\n",
      "+--------+------+--------------------+------+----+-----+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|\n",
      "+--------+------+--------------------+------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subsetting the columns from the DataFrame\n",
    "df.select(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bdf978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int32  \n",
      " 1   Survived     891 non-null    int32  \n",
      " 2   Pclass       891 non-null    int32  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int32  \n",
      " 7   Parch        891 non-null    int32  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int32(5), object(5)\n",
      "memory usage: 66.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1763da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dfc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "    \n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbeca7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a11ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|               714|\n",
      "|   mean| 29.69911764705882|\n",
      "| stddev|14.526497332334035|\n",
      "|    min|              0.42|\n",
      "|    25%|              20.0|\n",
      "|    50%|              28.0|\n",
      "|    75%|              38.0|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db9b3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = df.select(mean('Age')).collect()\n",
    "# mean_age[0][0]\n",
    "df = df.na.fill(mean_age[0][0],subset=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f66d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11230213",
   "metadata": {},
   "source": [
    "The Name and Ticket columns are not needed for out analysis, hence we will remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e76c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Name', 'Ticket', 'Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "099f9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+-------+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+--------+------+------+----+-----+-----+-------+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|          2|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "+-----------+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09479db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6007d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(SibSp, Parch)|\n",
      "+-------------------+\n",
      "|0.41483769862015635|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "# df.stat.corr(\"Quantity\", \"UnitPrice\")\n",
    "df.select(corr('SibSp', 'Parch')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a2a078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|       Q|\n",
      "|    null|\n",
      "|       C|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Embarked').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b987aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc\n",
    "em_mode = df.groupBy('Embarked').count().sort(desc('count')).collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9900b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill(em_mode,subset=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3f56a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   Sex|\n",
      "+------+\n",
      "|female|\n",
      "|  male|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Sex').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acd482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df = df.withColumn(\"Sex\", when(col(\"Sex\")=='male', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ebdd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "|PassengerId|Survived|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "|          0|       0|     0|  0|  0|    0|    0|   0|       2|\n",
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479be236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2113b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "|PassengerId|Survived|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "|          0|       0|     0|  0|  0|    0|    0|   0|       0|\n",
      "+-----------+--------+------+---+---+-----+-----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98b2ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---+----+-----+-----+-------+--------+\n",
      "|PassengerId|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+--------+------+---+----+-----+-----+-------+--------+\n",
      "|          1|       0|     3|  1|22.0|    1|    0|   7.25|       S|\n",
      "|          2|       1|     1|  0|38.0|    1|    0|71.2833|       C|\n",
      "|          3|       1|     3|  0|26.0|    0|    0|  7.925|       S|\n",
      "|          4|       1|     1|  0|35.0|    1|    0|   53.1|       S|\n",
      "|          5|       0|     3|  1|35.0|    0|    0|   8.05|       S|\n",
      "+-----------+--------+------+---+----+-----+-----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d762695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1a79eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "catCols = [\"Sex\", \"Embarked\"]\n",
    "for c in catCols:\n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+\"_index\").setHandleInvalid(\"skip\")\n",
    "    encoder = OneHotEncoder(inputCol=c+\"_index\", outputCol=c+\"_vec\", dropLast=False)\n",
    "    stages += [indexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8714394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns_vec = [c + \"_vec\" for c in catCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9368d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68eee1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42cc98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = categoricalColumns_vec + numCols\n",
    "assembler = VectorAssembler(inputCols = assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98e211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = prepPipeline.fit(df)\n",
    "data = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413a83a",
   "metadata": {},
   "source": [
    "## Save Transformation Pipeline\n",
    "pipelineModel.save(\"/mnt/<YOURMOUNTEDSTORAGE>/pipeline\")\n",
    "    \n",
    "display(dbutils.fs.ls(\"/mnt/<YOURMOUNTEDSTORAGE>/pipeline\"))\n",
    "\n",
    "## Read in Transformation Pipeline\n",
    "    \n",
    "from pyspark.ml import PipelineModel\n",
    "    \n",
    "pipelineModel = PipelineModel.load(\"/mnt/<YOURMOUNTEDSTORAGE>/pipeline\")\n",
    "    \n",
    "dataset = pipelineModel.transform(dataset)\n",
    "    \n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4eb94b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Survived|            features|\n",
      "+--------+--------------------+\n",
      "|       0|[1.0,0.0,1.0,0.0,...|\n",
      "|       1|[0.0,1.0,0.0,1.0,...|\n",
      "|       1|(10,[1,2,5,6,9],[...|\n",
      "|       1|[0.0,1.0,1.0,0.0,...|\n",
      "|       0|(10,[0,2,5,6,9],[...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selectedcols = [\"Survived\", \"features\"]# + cols\n",
    "data = data.select(selectedcols)\n",
    "##dataset.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fb9a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[1.0,0.0,1.0,0.0,...|\n",
      "|[0.0,1.0,0.0,1.0,...|\n",
      "|(10,[1,2,5,6,9],[...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "|(10,[0,2,5,6,9],[...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('features').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e308d9",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "train, test = data.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "695ffd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Survived|            features|\n",
      "+--------+--------------------+\n",
      "|       0|(10,[0,2,5,6],[1....|\n",
      "|       0|(10,[0,2,5,6],[1....|\n",
      "|       0|(10,[0,2,5,6],[1....|\n",
      "|       0|(10,[0,2,5,6],[1....|\n",
      "|       0|(10,[0,2,5,6,9],[...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcaab1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1935aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.3555, 1.3555, -0.272, 0.353, 0.0062, -0.942, -0.0374, -0.4003, -0.1412, 0.0035])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "416b568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3536835811676875"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "694113eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lrModel.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd2b3070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|(10,[0,2,5,6],[1....|[0.67273131754455...|[0.66211447685265...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....|[1.26733272663847...|[0.78028581280714...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....|[1.26733272663847...|[0.78028581280714...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....|[2.44473591992502...|[0.92017564558902...|       0.0|\n",
      "|       0|(10,[0,2,5,6,9],[...|[0.23518260931702...|[0.55852613975517...|       0.0|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbbe2be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.853582554517134, 0.6928104575163399]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.fMeasureByLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "944a9c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986351289599006"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.weightedFMeasure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af87e7",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1815c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol='features',\n",
    "                           labelCol='Survived',\n",
    "                           maxDepth=5,\n",
    "                           maxBins=4,\n",
    "                           impurity='gini')\n",
    "dtModel = dt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa8461a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91fd58d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------+--------------------+----------+\n",
      "|Survived|            features|rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+-------------+--------------------+----------+\n",
      "|       0|(10,[0,2,5,6],[1....|  [46.0,21.0]|[0.68656716417910...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....| [249.0,37.0]|[0.87062937062937...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....| [249.0,37.0]|[0.87062937062937...|       0.0|\n",
      "|       0|(10,[0,2,5,6],[1....| [249.0,37.0]|[0.87062937062937...|       0.0|\n",
      "|       0|(10,[0,2,5,6,9],[...|  [46.0,21.0]|[0.68656716417910...|       0.0|\n",
      "+--------+--------------------+-------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7386a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(10, {0: 0.6559, 2: 0.0275, 3: 0.0134, 5: 0.1863, 6: 0.0284, 7: 0.0454, 8: 0.0212, 9: 0.022})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292b15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ce61748c4639de6d77d32000f7ef72553a4257d5c14a7cd80f77c29dd2b22b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
